% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\usepackage{graphicx}
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}
\begin{document}

% Graphics Path

\graphicspath{ {/home/anantgupta/Documents/Competitions/ncmlai/} }

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Collaborative Filtering using AutoEncoders}

%for single author (just remove % characters)
\author{
{\rm Anant Gupta}\\
Morgan Stanley
%\and
%{\rm Second Name}\\
%Second Institution
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
\thispagestyle{empty}


\subsection*{Abstract}
The current methodologies for collaborative filtering rely on linear methodologies like Singular Value Decomposition (SVD) etc. There are several drawbacks with this approach. First, this method leaves out the non-linear relationships between the user and item data. Given the inreasing complexities of products and users ( because of increase in available products and online marketplaces ) we
have to tap into complex relationships as well. Second, as we explore larger user datasets, the matrix becomes sparse. Linear operations become counter productive with sparse matrices. The use of autoencoders for collaborative filtering allows us to not only find relationships between 
users and products but also find similarities between the users and items themselves. This allows us to use the same model for a new product as well

\subsection*{Keywords}
Recommender Systems, AutoEncoders, Similarity

\section{Introduction}

There has been an increase in choices that are available to users and with the increase in digital adoption, even the user base is increasing. This has resulted in a very large sparse relationship matrix between users and items. There have been several problems in using this dataset
for performing collaborative filtering

\begin{itemize}
\item \textbf{Sparse Data} \\
Sparsity is a big problem while working with large data. The relationships that come out, if they do, are not entirely accurate. This problem has been solved by grouping similar items together, but this beats the purpose of having a dedicated product recommendation

\item \textbf{Similar Products} \\
Product similarity is currently evaluated based on product features. Given the multitude of products available, different products have different features. Even if we are able to take all the possible features for all the products into consideration and come up with a clustering mechanism, the similarity measure is based on intrinsic features of the products and not on the user buy patterns. For a recommender system, the similaity metric of products based on user transactions is not taken into consideration with the current deep recommender systems

\item \textbf{Similar Users} \\
Calculating similarity between users is an important step for a product company to profile its userbase. It allows an organization to check temporal changes to the patterns of a particular profile of users and adjust their products accordingly. In current recommender systems, the user similarity is based on the actual products bought, but not on the bucketing of non-related products themselves.

\end{itemize}

\subsection{AutoEncoders}
Autoencoders are a powerful concept in the realm of deep learning. They are particularly strong in deriving latent features from an input dataset. The latent features derived capture all the intricate relationships between the input feature vectors. This is a significant win over the linear methodologies applied for feature generation like PCA etc. It is particularly helpful for compression techniques and feature generation. 

\begin{figure}[h!]
\includegraphics[width=8cm,height=5cm]{SimpleAutoEncoder.jpg}
\end{figure}

However, the use of it in recommender system is unheard of because it requires the same input and output. We can either pass the user data ot the item data. What we would like to have is an autoencoder that will generate the latent features for user and item data based on the input relationships between the user and item. We dont want the latent features for users and items to be generated in isolation. This will not solve the issues that we had highlighted earlier

\subsection{New Methodology}
For achieving, this we will be using the principle of autoencoders in a slightly different and unique way

\begin{figure}[h!]
\includegraphics[width=8cm,height=5cm]{UpdatedAutoEncoder.jpg}
\end{figure}

The above image has 2 extra layers in between. The traversal through each of the layers holds different significance


\begin{itemize}
\item \textbf{Layer 1 : User Input}

\begin{figure}[h!]
\includegraphics[width=4cm,height=4cm]{UserItemData.jpg}
\end{figure}

The above image is the tabular data for user and item columns. We take the user data out of it as a vector \textbf{U_{n,uo}}

\begin{itemize}
\item \textbf{n} denotes number of rows
\item \textbf{uo} denotes the length of feature vector for each user
\end{itemize}

\item \textbf{Layer 2: User Embedding}

This is the first hidden layer : \textbf{UEmbedding_{n,ue}}
\begin{itemize}
\item \textbf{ue} denotes the condensed user vector space
\end{itemize}

\item \textbf{Layer 3}

This is the second hidden layer : \textbf{UHidden_{ue,ui}}
\begin{itemize}
\item \textbf{ui} denotes the innermost vector space for user
\end{itemize}

\item \textbf{Layer 4 : User Item Matrix}

This is the innermost layer which maintains the relationship between the condensed user and item vector spaces \textbf{UserItem_{ui,ii}}

\begin{itemize}
\item \textbf{ii} denotes the innermost vector space for items
\end{itemize}

\item \textbf{Layer 5}

This is the fourth hidden layer : \textbf{IHidden_{ii,ie}}

\begin{itemize}
\item \textbf{ie} denotes the condensed item vector space
\end{itemize}

\item \textbf{Layer 6 : Item Embedding}

This is the Item Embedding which maintains the item latent vectors : \textbf{IEmbedding_{n,ie}}

\item \textbf{Layer 7 : Items}

This is final Item vector which is the data from the Item vector from the input table \textbf{I{n,io}}
\begin{itemize}
\item \textbf{io} denotes the original item vector space
\end{itemize}

\end{itemize}

Let us focus particularly on the UserEmbedding the ItemEmbedding layers and try to understand what they are capturing

\section {OUTPUT}

\subsection {USER EMBEDDING}

\begin{figure}[h!]
\includegraphics[width=8cm,height=5cm]{UserEmbedding.jpg}
\end{figure}

If we look at the flow diagram above, the autoencoder is trying to minimise the errors of matching the user vector to the item vector. This forces the first hidden layer, the UserEmbedding to capture the latent features of the user vector space in a smaller vector space while bein able to create the same item mapping. This reduction of features has not happened in an unsupervised fashion as is done in Clustering or PCA, but in a supervised fashion


\textbf{U_{n,uo} -> U_{n,ue}  }
\begin{itemize}
\item where ue << uo
\end{itemize}

We see that the same user can have different points in the UserEmbedding space, so we will take the centroid of all the vectors of a user to come up with 

\textbf{U_{nu,ue}}
\begin{itemize}
\item nu denotes the unique number of users
\end{itemize}

U_{nu,ue} = \sum_{i=1}^{nu}{x^i} \div {urows}

\begin{itemize}
\item urows denotes the number of data points for a particular user U_{i}
\end{itemize}


\subsection {ITEM EMBEDDING}

\begin{figure}[h!]
\includegraphics[width=8cm,height=5cm]{ItemEmbedding.jpg}
\end{figure}

If we look at the above flow diagram, the autoencoder creates the item embedding as the last layer before the final item vector is recreated. This embedded layer dos not just include the final recreation, but because of the back propagation, it tries to capture the latent features of the item vector space in a smaller space while retaining the user item relationships. This again leads to feature reduction in a supervised fashion

\textbf{I_{n,io} -> I_{n,ie} }
\begin{itemize}
\item where ie << io
\end{itemize}

We see that the same item can have different points in the ItemEmbedding space, so we will take the centroid of all the vectors of an item to come up with 

\textbf{I_{ni,ie}}
\begin{itemize}
\item ni denotes the unique number of items
\end{itemize}

I_{ni,ie} = \sum_{i=1}^{ni}{x^i} \div {irows}
\begin{itemize}
\item where irows denotes the number of data points for a particular item I_{i}
\end{itemize}

\section{APPLICATIONS}
\subsection{Use/Item Similarity}

Once the User Embedding feature vector is calculated, it can be used to capture similar users in different ways
\subsubsection { Clustering }
We can apply a clustering technique to find groups of similar users

\subsubsection { Distance Metric }
We can apply distance metric to answer which users are closest to a particular user

\subsubsection { AutoEncoding for 2D Visualization }
We can again apply the normal autoencoder or TSNE to the User Embedding to reduce the vector space to two dimensions to visualize all the users in one graph


\subsection{Onboarding User/Item}
It is possible that we do not want to train the model very often, and if we want to get a recommendation for a new user, we can take the average of existing users who are similar based on intrinsic user features. This can then be used to come up with item recommendations

\subsection{Item Recommendation}
The holy grail has been to find out the items that we need to recommend to the users. We simply to find the point in the Item Embedding space corresponding to the User. Once we get the point we can find all items that are closest to the point with a threshold and that becomes our recommendations


\section {TESTING}

For testing, I considered an open source Movie Rating dataset. This dataset has data for thousands of users for thousands of movies. 

{\footnotesize \bibliographystyle{acm}
\bibliography{../common/bibliography}}


\theendnotes

\end{document}








