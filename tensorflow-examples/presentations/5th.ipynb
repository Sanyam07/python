{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FullData=pd.DataFrame(columns=['stock','date','close'])\n",
    "for curFile in os.listdir('HISTORICAL_DATA'):\n",
    "    print(\"started processing {}\".format(curFile))\n",
    "    try:\n",
    "        curData=pd.read_csv('HISTORICAL_DATA/{}'.format(curFile),sep=',')\n",
    "        curData=curData[['Date','close']]\n",
    "        curData.columns=['date','close']\n",
    "        curData['stock']=curFile.replace('_data.csv','')\n",
    "        curData.sort_values('date',inplace=True)\n",
    "        prices=curData['close']\n",
    "        curData['returns']=prices / prices.shift(1) - 1\n",
    "        FullData=pd.concat([FullData,curData])\n",
    "    except:\n",
    "        print(\"Error with {}\".format(curFile))\n",
    "\n",
    "# Pre Processing\n",
    "FullData.fillna(0,inplace=True)\n",
    "\n",
    "# Converting to Pivot\n",
    "from datetime import datetime\n",
    "FullData['year']=FullData['date'].map(lambda x:  datetime.strptime(x,'%Y-%m-%d').year)\n",
    "FullData['month']=FullData['date'].map(lambda x:  datetime.strptime(x,'%Y-%m-%d').month)\n",
    "FullData['dateVal']=FullData['date'].map(lambda x:  datetime.strptime(x,'%Y-%m-%d'))\n",
    "\n",
    "FullDataPivot=FullData.pivot(index='date', columns='stock', values='returns')\n",
    "FullDataPivot.fillna(0,inplace=True)\n",
    "\n",
    "# Correlation Data\n",
    "corrData=FullDataPivot.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anantgupta/.conda/envs/python2/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/anantgupta/.conda/envs/python2/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get the Market MAP from the S&P 500 companies\n",
    "data=pd.read_csv('/home/anantgupta/Documents/Competitions/5th/sandp500/all_stocks_5yr.csv')\n",
    "dataWithReturns=pd.DataFrame(columns=['Name','date','close','return'])\n",
    "\n",
    "# Get the return data\n",
    "data=data[['Name','close','date']]\n",
    "data.sort_values(['Name','close'],inplace=True)\n",
    "\n",
    "# Function to convert to returns\n",
    "for x in data['Name'].unique():\n",
    "    curData=data[data['Name']==x]\n",
    "    curData.sort_values('close',inplace=True)\n",
    "    prices=curData['close']\n",
    "    curData['return']=prices / prices.shift(1) - 1\n",
    "    dataWithReturns=pd.concat([dataWithReturns,curData])\n",
    "    \n",
    "# Fill the data with 0 for initial returns\n",
    "dataWithReturns.fillna(0,inplace=True)\n",
    "dataWithReturns['year']=dataWithReturns['date'].map(lambda x : datetime.strptime(x,'%Y-%m-%d').year)\n",
    "dataWithReturns['month']=dataWithReturns['date'].map(lambda x : datetime.strptime(x,'%Y-%m-%d').month)\n",
    "dataWithReturns['day']=dataWithReturns['date'].map(lambda x : datetime.strptime(x,'%Y-%m-%d').day)\n",
    "dataPivot=dataWithReturns.pivot(index='date',columns='Name',values='return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CAPM\n",
    "monthPivot=dataWithReturns[(dataWithReturns['year']==2018) & (dataWithReturns['month']==1)].pivot(index='date',columns='Name',values='return')\n",
    "monthPivot.fillna(0,inplace=True)\n",
    "monthEndAndStart=monthPivot.values[[0,-1],:]\n",
    "returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(505)]).reshape(505,1)\n",
    "returnData=np.nan_to_num(returnData)\n",
    "covMatrix=np.cov(monthPivot.values.T)\n",
    "\n",
    "returnRiskArray=[]\n",
    "\n",
    "#for maxValue in [0.04,0.05,0.06,0.07,0.08,0.09,0.1]:\n",
    "for maxValue in [0.05]:\n",
    "    ranges=[]\n",
    "    for x in range(20):\n",
    "        ranges.append(np.linspace(0,maxValue,2))\n",
    "\n",
    "    answer = [v for v in itertools.product(*ranges) if sum(v) > 0.7 and sum(v) < 0.8]\n",
    "    returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(505)]).reshape(505,1)\n",
    "    returnData=np.nan_to_num(returnData)\n",
    "    for randomIterations in range(10):\n",
    "        curStockIndex=random.sample(set(range(505)), 20)\n",
    "        for w1 in answer:\n",
    "            curDict={curStockIndex[x]:w1[x] for x in range(len(w1))}\n",
    "            weights=np.array([curDict[x] if x in curStockIndex else 0.0 for x in range(505)]).reshape(505,1)\n",
    "            covMatrix=np.cov(monthPivot.values.T)\n",
    "            returnPortfolio=np.matmul(returnData.T,weights)\n",
    "            devPortfolio=np.matmul(np.matmul(weights.T,covMatrix),weights)\n",
    "            returnRiskArray.append([weights,returnPortfolio[0][0],np.sqrt(devPortfolio[0][0])])\n",
    "            \n",
    "# Plotting the CAPM line\n",
    "plt.scatter([x[2] for x in returnRiskArray],[x[1] for x in returnRiskArray])\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Return 0.03811738759680715, risk :  0.7474532181968696\n",
    "[x[0] for x in returnRiskArray if x[1] < 0.04 and x[1] > 0.037 and x[2] > 0.5 and x[2] < 0.8 ]\n",
    "optimalWeights=[x[0] for x in returnRiskArray if x[1]==0.03811738759680715 and x[2]==0.7474532181968696]\n",
    "print(optimalWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter([x[2] for x in returnRiskArray],[x[1] for x in returnRiskArray])\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "[[x[1],x[2]] for x in returnRiskArray if x[1] < 0.04 and x[1] > 0.035 and x[2] > 0.4 and x[2] < 0.55 ]\n",
    "optimalWeights=[x[0] for x in returnRiskArray if x[1]==0.035122917453329384 and x[2]==0.5370018533265882]\n",
    "np.array(optimalWeights).reshape(1,505)[0]\n",
    "\n",
    "0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.05, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.05, 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.05, 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
    "       0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will run deep portfolio to come up with the corresponding market map for the stocks and check what are the insights that we get\n",
    "\n",
    "# 1) MARKET MAP\n",
    "monthPivot=dataWithReturns.pivot(index='date',columns='Name',values='return')\n",
    "monthPivot.fillna(0,inplace=True)\n",
    "monthPivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class TFAutoEncoder():\n",
    "    # INIT function\n",
    "    def __init__(self,X,learningRate,ratio1,ratio2):\n",
    "        # Input Data\n",
    "        self.X=X\n",
    "        \n",
    "        # Input Placeholder\n",
    "        self.x_input=tf.placeholder(\"float32\",(None,X.shape[1]))\n",
    "        \n",
    "        # Intermediate Variables\n",
    "        self.encoder_1_weight=tf.Variable(tf.random_uniform([self.X.shape[1],self.X.shape[1]/ratio1]))\n",
    "        self.encoder_2_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1,self.X.shape[1]/ratio2]))\n",
    "        self.decoder_1_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio2,self.X.shape[1]/ratio1]))\n",
    "        self.decoder_2_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1,self.X.shape[1]]))\n",
    "        self.encoder_1_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1]))\n",
    "        self.encoder_2_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio2]))\n",
    "        self.decoder_1_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1]))\n",
    "        self.decoder_2_bias=tf.Variable(tf.random_uniform([self.X.shape[1]]))\n",
    "                \n",
    "        self.encoder_1=tf.add(tf.matmul(self.x_input,self.encoder_1_weight),self.encoder_1_bias)\n",
    "        self.encoder_2=tf.nn.sigmoid(tf.add(tf.matmul(self.encoder_1,self.encoder_2_weight),self.encoder_2_bias))\n",
    "        self.decoder_1=tf.nn.sigmoid(tf.add(tf.matmul(self.encoder_2,self.decoder_1_weight),self.decoder_1_bias))\n",
    "        self.decoder_2=tf.add(tf.matmul(self.decoder_1,self.decoder_2_weight),self.decoder_2_bias)\n",
    "        \n",
    "        self.loss=tf.reduce_mean(tf.pow(self.x_input-self.decoder_2,2))\n",
    "        self.optimizer=tf.train.GradientDescentOptimizer(learningRate).minimize(self.loss)\n",
    "        self.init=tf.global_variables_initializer()\n",
    "        \n",
    "    def train(self,execRange=1000):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            for curIteration in range(execRange):\n",
    "                _,curLoss,self.recreatedData=sess.run([self.optimizer,self.loss,self.decoder_2],feed_dict={self.x_input:self.X})\n",
    "                if(curIteration % 1000==0):\n",
    "                    print(\"The loss at step {} is {}\".format(curIteration,curLoss))\n",
    "                \n",
    "if __name__==\"__main__\":\n",
    "    # Input Data\n",
    "    data=monthPivot.values\n",
    "    ae=TFAutoEncoder(data,0.01,10,20)\n",
    "    ae.train(50000)\n",
    "    \n",
    "    # We will check the recreated the matrix and check which one has the least RMSE\n",
    "    rmseDict=[]\n",
    "    for x in range(data.shape[1]):\n",
    "        rmseDict.append([monthPivot.columns.values[x],math.sqrt(sum([(xi-yi)**2 for xi,yi in zip(data[:,x],ae.recreatedData[:,x])]))])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stocks that explain the market a lot\n",
    "NameList=pd.DataFrame(rmseDict,columns=['Name','RMSE']).sort_values('RMSE')[0:50].values[:,0]\n",
    "monthPivot=dataWithReturns[(dataWithReturns['year']==2018) & (dataWithReturns['month']==1) & (dataWithReturns['Name'].isin(NameList))].pivot(index='date',columns='Name',values='close')\n",
    "monthPivot.fillna(0,inplace=True)\n",
    "monthEndAndStart=monthPivot.values[[0,-1],:]\n",
    "returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(50)]).reshape(50,1)\n",
    "returnData=np.nan_to_num(returnData)\n",
    "covMatrix=np.cov(monthPivot.values.T)\n",
    "\n",
    "returnRiskArray=[]\n",
    "\n",
    "for maxValue in [0.04,0.05,0.06,0.07,0.08,0.09,0.1]:\n",
    "    ranges=[]\n",
    "    for x in range(20):\n",
    "        ranges.append(np.linspace(0,maxValue,2))\n",
    "\n",
    "    answer = [v for v in itertools.product(*ranges) if sum(v) > 0.7 and sum(v) < 0.8]\n",
    "    returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(50)]).reshape(50,1)\n",
    "    returnData=np.nan_to_num(returnData)\n",
    "    for randomIterations in range(10):\n",
    "        curStockIndex=random.sample(set(range(50)), 20)\n",
    "        for w1 in answer:\n",
    "            curDict={curStockIndex[x]:w1[x] for x in range(len(w1))}\n",
    "            weights=np.array([curDict[x] if x in curStockIndex else 0.0 for x in range(50)]).reshape(50,1)\n",
    "            covMatrix=np.cov(monthPivot.values.T)\n",
    "            returnPortfolio=np.matmul(returnData.T,weights)\n",
    "            devPortfolio=np.matmul(np.matmul(weights.T,covMatrix),weights)\n",
    "            returnRiskArray.append([weights,returnPortfolio[0][0],np.sqrt(devPortfolio[0][0])])\n",
    "            if(len(returnRiskArray) > 1000000):\n",
    "                break\n",
    "        if(len(returnRiskArray) > 1000000):\n",
    "            break\n",
    "    if(len(returnRiskArray) > 1000000):\n",
    "            break\n",
    "            \n",
    "# Plotting the CAPM line\n",
    "plt.scatter([x[2] for x in returnRiskArray],[x[1] for x in returnRiskArray])\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Return 0.03811738759680715, risk :  0.7474532181968696\n",
    "#[x[0] for x in returnRiskArray if x[1] < 0.04 and x[1] > 0.037 and x[2] > 0.5 and x[2] < 0.8 ]\n",
    "#optimalWeights=[x[0] for x in returnRiskArray if x[1]==0.03811738759680715 and x[2]==0.7474532181968696]\n",
    "#print(optimalWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bottom 50 stocks\n",
    "NameList=pd.DataFrame(rmseDict,columns=['Name','RMSE']).sort_values('RMSE')[-50:].values[:,0]\n",
    "monthPivot=dataWithReturns[(dataWithReturns['year']==2018) & (dataWithReturns['month']==1) & (dataWithReturns['Name'].isin(NameList))].pivot(index='date',columns='Name',values='close')\n",
    "monthPivot.fillna(0,inplace=True)\n",
    "monthEndAndStart=monthPivot.values[[0,-1],:]\n",
    "returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(50)]).reshape(50,1)\n",
    "returnData=np.nan_to_num(returnData)\n",
    "covMatrix=np.cov(monthPivot.values.T)\n",
    "\n",
    "returnRiskArray=[]\n",
    "\n",
    "#for maxValue in [0.04,0.05,0.06,0.07,0.08,0.09,0.1]:\n",
    "for maxValue in [0.05]:\n",
    "    ranges=[]\n",
    "    for x in range(20):\n",
    "        ranges.append(np.linspace(0,maxValue,2))\n",
    "\n",
    "    answer = [v for v in itertools.product(*ranges) if sum(v) > 0.7 and sum(v) < 0.8]\n",
    "    returnData=np.array([(monthEndAndStart[1][x] - monthEndAndStart[0][x])/monthEndAndStart[0][x] for x in range(50)]).reshape(50,1)\n",
    "    returnData=np.nan_to_num(returnData)\n",
    "    for randomIterations in range(10):\n",
    "        curStockIndex=random.sample(set(range(50)), 20)\n",
    "        for w1 in answer:\n",
    "            curDict={curStockIndex[x]:w1[x] for x in range(len(w1))}\n",
    "            weights=np.array([curDict[x] if x in curStockIndex else 0.0 for x in range(50)]).reshape(50,1)\n",
    "            covMatrix=np.cov(monthPivot.values.T)\n",
    "            returnPortfolio=np.matmul(returnData.T,weights)\n",
    "            devPortfolio=np.matmul(np.matmul(weights.T,covMatrix),weights)\n",
    "            returnRiskArray.append([weights,returnPortfolio[0][0],np.sqrt(devPortfolio[0][0])])\n",
    "            \n",
    "# Plotting the CAPM line\n",
    "plt.scatter([x[2] for x in returnRiskArray],[x[1] for x in returnRiskArray])\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Return 0.03811738759680715, risk :  0.7474532181968696\n",
    "#[x[0] for x in returnRiskArray if x[1] < 0.04 and x[1] > 0.037 and x[2] > 0.5 and x[2] < 0.8 ]\n",
    "#optimalWeights=[x[0] for x in returnRiskArray if x[1]==0.03811738759680715 and x[2]==0.7474532181968696]\n",
    "#print(optimalWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Create the LATENT FEATURES for each stock\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class TFAutoEncoder():\n",
    "    # INIT function\n",
    "    def __init__(self,X,learningRate,ratio1,ratio2):\n",
    "        # Input Data\n",
    "        self.X=X\n",
    "        \n",
    "        # Input Placeholder\n",
    "        self.x_input=tf.placeholder(\"float32\",(None,X.shape[1]))\n",
    "        \n",
    "        # Intermediate Variables\n",
    "        self.encoder_1_weight=tf.Variable(tf.random_uniform([self.X.shape[1],self.X.shape[1]/ratio1]))\n",
    "        self.encoder_2_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1,self.X.shape[1]/ratio2]))\n",
    "        self.decoder_1_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio2,self.X.shape[1]/ratio1]))\n",
    "        self.decoder_2_weight=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1,self.X.shape[1]]))\n",
    "        self.encoder_1_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1]))\n",
    "        self.encoder_2_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio2]))\n",
    "        self.decoder_1_bias=tf.Variable(tf.random_uniform([self.X.shape[1]/ratio1]))\n",
    "        self.decoder_2_bias=tf.Variable(tf.random_uniform([self.X.shape[1]]))\n",
    "                \n",
    "        self.encoder_1=tf.add(tf.matmul(self.x_input,self.encoder_1_weight),self.encoder_1_bias)\n",
    "        self.encoder_2_data=tf.add(tf.matmul(self.encoder_1,self.encoder_2_weight),self.encoder_2_bias)\n",
    "        self.encoder_2=tf.nn.sigmoid(tf.add(tf.matmul(self.encoder_1,self.encoder_2_weight),self.encoder_2_bias))\n",
    "        self.decoder_1=tf.nn.sigmoid(tf.add(tf.matmul(self.encoder_2,self.decoder_1_weight),self.decoder_1_bias))\n",
    "        self.decoder_2=tf.add(tf.matmul(self.decoder_1,self.decoder_2_weight),self.decoder_2_bias)\n",
    "        \n",
    "        self.loss=tf.reduce_mean(tf.pow(self.x_input-self.decoder_2,2))\n",
    "        self.optimizer=tf.train.GradientDescentOptimizer(learningRate).minimize(self.loss)\n",
    "        self.init=tf.global_variables_initializer()\n",
    "        \n",
    "    def train(self,execRange=1000):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            for curIteration in range(execRange):\n",
    "                _,curLoss,self.encoderData=sess.run([self.optimizer,self.loss,self.encoder_2_data],feed_dict={self.x_input:self.X})\n",
    "                if(curIteration % 1000==0):\n",
    "                    print(\"The loss at step {} is {}\".format(curIteration,curLoss))\n",
    "                \n",
    "if __name__==\"__main__\":\n",
    "    # Input Data\n",
    "    monthPivot=dataWithReturns.pivot(index='date',columns='Name',values='return')\n",
    "    monthPivot.fillna(0,inplace=True)\n",
    "    data=monthPivot.values.T\n",
    "    ae=TFAutoEncoder(data,0.1,10,20)\n",
    "    ae.train(50000)\n",
    "    recreatedData=ae.encoderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will try to find out the stocks that are most related to each other\n",
    "\n",
    "\n",
    "# For the NVIDIA stock, find out the stock with whih it has the max correlation\n",
    "#nvidiaCorellation=monthPivot.corr()['NVDA']\n",
    "\n",
    "# Most uncorrelated\n",
    "#print(nvidiaCorellation.sort_values()[0:10])\n",
    "#EXPE   -0.074563 : Expedia\n",
    "#DIS    -0.062784 : Walt Disney\n",
    "#SNA    -0.060869 : SNA : Heavy Duty machinery\n",
    "#UHS    -0.060471 : Uniuversal HealthCare Services\n",
    "#ESS    -0.060316 : Essex Property\n",
    "#WU     -0.060296\n",
    "#MYL    -0.055252\n",
    "#WBA    -0.054852\n",
    "#UDR    -0.054733\n",
    "#EXR    -0.053736\n",
    "\n",
    "# Most correlated\n",
    "#print(nvidiaCorellation.sort_values())\n",
    "#ETFC    0.111365\n",
    "#HPE     0.138044\n",
    "#HRB     0.152764\n",
    "#RSG     0.155990\n",
    "#WLTW    0.190318\n",
    "#XEL     0.196631 : Excel Energy\n",
    "#SYK     0.199469 : Stryker Medial technologies, knee plants\n",
    "#CMA     0.228179 : Comerica Business Bank\n",
    "#UNM     0.295471 : UNUM Insurance Company\n",
    "#NVDA    1.000000\n",
    "\n",
    "# Now we will be usin the latent features\n",
    "recreatedData=ae.encoderData\n",
    "latentcorr=np.corrcoef(recreatedData)\n",
    "latentcorrData=pd.DataFrame(zip(monthPivot.columns,latentcorr[346]),columns=['Name','corr']).sort_values('corr')\n",
    "\n",
    "# Low correlation\n",
    "#latentcorrData.head(10)['Name'].values\n",
    "#APTV : APTV Electrical systems\n",
    "#DWDP : Du Pont\n",
    "#VZ : Verizon\n",
    "#KO : Coca Cola\n",
    "#BHF : BrighHouse Annuities\n",
    "\n",
    "# High correlation\n",
    "#latentcorrData.tail(10)['Name'].values\n",
    "\n",
    "#FB : Facebook\n",
    "#AVGO : Broadcom digital semiconductors\n",
    "#AMD : AMD Micro Devices\n",
    "#FCX : FreePort\n",
    "#NFLX : NetFlix\n",
    "#NVDA\n",
    "\n",
    "#For NVIDIA checking where does EA sports sit before and after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to optimize the portfolio rejig\n",
    "\n",
    "x_returns=tf.placeholder(\"float32\",(None,100))\n",
    "x_weights=tf.placeholder(\"float32\",(None,100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network is 23.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAS4CAYAAADBgtpzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npH4BSDJtKslvHBAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b08017950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Util functions\n",
    "\n",
    "\n",
    "# function to plot the images after during testing phase\n",
    "def plot_images(images, title, no_i_x, no_i_y=3):\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    fig.canvas.set_window_title(title)\n",
    "    images = np.array(images).reshape(-1, 5, 5)\n",
    "    images = np.pad(\n",
    "        images, ((0, 0), (1, 1), (1, 1)), 'constant', constant_values=-1)\n",
    "    for i in range(no_i_x):\n",
    "        for j in range(no_i_y):\n",
    "            ax = fig.add_subplot(no_i_x, no_i_y, no_i_x * j + (i + 1))\n",
    "            ax.matshow(images[no_i_x * j + i], cmap=\"gray\")\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "\n",
    "            if j == 0 and i == 0:\n",
    "                ax.set_title(\"Real\")\n",
    "            elif j == 0 and i == 1:\n",
    "                ax.set_title(\"Distorted\")\n",
    "            elif j == 0 and i == 2:\n",
    "                ax.set_title(\"Reconstructed\")\n",
    "\n",
    "\n",
    "#  Dummy Data\n",
    "perfect_data = {\n",
    "    \"P\": [\n",
    "        1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1,\n",
    "        -1, -1, -1, -1\n",
    "    ],\n",
    "    \"Y\": [\n",
    "        1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1,\n",
    "        -1, -1, -1, 1, -1, -1\n",
    "    ],\n",
    "    \"T\": [\n",
    "        1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1,\n",
    "        -1, -1, 1, -1, -1\n",
    "    ],\n",
    "    \"H\": [\n",
    "        1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1,\n",
    "        -1, -1, -1, 1\n",
    "    ],\n",
    "    \"O\": [\n",
    "        1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1,\n",
    "        1, 1, 1, 1\n",
    "    ],\n",
    "    \"N\": [\n",
    "        1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1,\n",
    "        -1, -1, -1, 1\n",
    "    ]\n",
    "}\n",
    "\n",
    "#  Pre-Process Data\n",
    "\n",
    "#  Data Parameters\n",
    "\n",
    "# Hopfield networks can hold about 0.138 \\* n_neurons for better denoising <br>\n",
    "# 0.138 \\* n_neurons = 0.138 \\* 25 = 3.45 ~ 3 <br>\n",
    "n_train = 3\n",
    "\n",
    "n_test = 100\n",
    "\n",
    "# no of images to show in output plot\n",
    "n_train_disp = 10\n",
    "\n",
    "# Amount of distortion (0 < distort < 1)\n",
    "distort = 0.1\n",
    "\n",
    "# Size of image(width)\n",
    "n_side = 5\n",
    "\n",
    "# No of neurons\n",
    "n_neurons = n_side * n_side\n",
    "\n",
    "train_data = [np.array(d) for d in perfect_data.values()][:n_train]\n",
    "\n",
    "# Generate test data by adding noise to train data\n",
    "test_data = []\n",
    "for d in range(n_test):\n",
    "    r_i = np.random.randint(0, n_train)\n",
    "    base_pattern = np.array(train_data[r_i])\n",
    "    noise = 1 * (np.random.random(base_pattern.shape) > distort)\n",
    "    np.place(noise, noise == 0, -1)\n",
    "    noisy_pattern = np.multiply(base_pattern, noise)\n",
    "    test_data.append((base_pattern, noisy_pattern))\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "\n",
    "# Function to train the network using Hebbian learning rule\n",
    "def train(neu, training_data):\n",
    "    w = np.zeros([neu, neu])\n",
    "    for data in training_data:\n",
    "        w += np.outer(data, data)\n",
    "    for diag in range(neu):\n",
    "        w[diag][diag] = 0\n",
    "    return w\n",
    "\n",
    "\n",
    "# Function to test the network\n",
    "def test(weights, testing_data):\n",
    "    success = 0.0\n",
    "\n",
    "    output_data = []\n",
    "\n",
    "    for data in testing_data:\n",
    "        true_data = data[0]\n",
    "        noisy_data = data[1]\n",
    "        predicted_data = retrieve_pattern(weights, noisy_data)\n",
    "        if np.array_equal(true_data, predicted_data):\n",
    "            success += 1.0\n",
    "        output_data.append([true_data, noisy_data, predicted_data])\n",
    "\n",
    "    return (success / len(testing_data)), output_data\n",
    "\n",
    "\n",
    "# Function to retrieve individual noisy patterns\n",
    "def retrieve_pattern(weights, data, steps=10):\n",
    "    res = np.array(data)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        for i in range(len(res)):\n",
    "            raw_v = np.dot(weights[i], res)\n",
    "            if raw_v > 0:\n",
    "                res[i] = 1\n",
    "            else:\n",
    "                res[i] = -1\n",
    "    return res\n",
    "\n",
    "\n",
    "# Train\n",
    "W = train(n_neurons, train_data)\n",
    "\n",
    "# Test\n",
    "accuracy, op_imgs = test(W, test_data)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy of the network is %f\" % (accuracy * 100))\n",
    "\n",
    "# Plot test result\n",
    "plot_images(op_imgs, \"Reconstructed Data\", n_train_disp)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
