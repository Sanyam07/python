{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the data\n",
    "folders=['00000','01000','02000','03000']\n",
    "for curFolder in folders:\n",
    "    for curFile in os.listdir(curFolder):\n",
    "        curImg=cv2.imread('{0}/{1}'.format(curFolder,curFile))\n",
    "        curImg=cv2.resize(curImg,(128,128))\n",
    "        cv2.imwrite('{0}/{1}'.format(curFolder,curFile),curImg)\n",
    "    \n",
    "# Data for Aakash\n",
    "coloredFaces=[]\n",
    "curFolder='00000'\n",
    "for curFile in os.listdir(curFolder):\n",
    "    if(curFile[0]=='_'):\n",
    "        coloredFaces.append(curFile.replace('_',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Black and white \n",
    "\n",
    "# Data for training\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "folders=['00000']\n",
    "for curFolder in folders:\n",
    "    for curFile in os.listdir(curFolder):\n",
    "        curImg=cv2.imread('{0}/{1}'.format(curFolder,curFile))\n",
    "        trainX.append(curImg)\n",
    "        if(curFile[0]=='_'):\n",
    "            trainY.append(1)\n",
    "        else:\n",
    "            trainY.append(0)\n",
    "\n",
    "trainX=np.array(trainX)\n",
    "trainY=np.array(trainY)\n",
    "            \n",
    "# Model\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class faceClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(faceClass,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,16,(3,3), stride=1, padding=0).cuda()\n",
    "        self.conv2=nn.Conv2d(16,64,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max2=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv3=nn.Conv2d(64,256,(3,3), stride=1, padding=0).cuda()\n",
    "        self.conv4=nn.Conv2d(256,512,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max4=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv5=nn.Conv2d(512,512,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max5=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv6=nn.Conv2d(512,3,(3,3), stride=1, padding=0).cuda()\n",
    "        self.l1=nn.Linear(3*11*11,1).cuda()\n",
    "        self.sigm=nn.Sigmoid().cuda()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        out=self.conv1(inputs).cuda()\n",
    "        #out=self.max1(out).cuda()\n",
    "        out=self.conv2(out).cuda()\n",
    "        out=self.max2(out).cuda()\n",
    "        out=self.conv3(out).cuda()\n",
    "        #out=self.max3(out).cuda()\n",
    "        out=self.conv4(out).cuda()\n",
    "        out=self.max4(out).cuda()\n",
    "        out=self.conv5(out).cuda()\n",
    "        out=self.max5(out).cuda()\n",
    "        out=self.conv6(out).cuda()\n",
    "        #out=self.max6(out).cuda()\n",
    "        #print(\"Size of out is {0}\".format(out.size()))\n",
    "        out=self.l1(out.view(-1,3*11*11))\n",
    "        out=self.sigm(out)\n",
    "        return out\n",
    "\n",
    "model=faceClass().cuda()\n",
    "criterion = torch.nn.BCELoss(weight=torch.FloatTensor([0.99]).cuda())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "batchSize=16\n",
    "epochs=10000\n",
    "    \n",
    "train=0\n",
    "if(train==1):\n",
    "    numBatches=int(trainX.shape[0]/batchSize)\n",
    "    for curEpoch in range(epochs):\n",
    "        totalLoss=0\n",
    "        for curBatch in range(numBatches):\n",
    "            model.zero_grad()\n",
    "            X=Variable(torch.from_numpy(trainX[curBatch*batchSize:(curBatch+1)*batchSize].reshape(batchSize,3,128,128).astype(np.float32))).cuda()\n",
    "            Y=Variable(torch.from_numpy(trainY[curBatch*batchSize:(curBatch+1)*batchSize].astype(np.float32))).cuda()\n",
    "            output=model(X).cuda()\n",
    "            curLoss=criterion(output,Y)\n",
    "            totalLoss+=curLoss.item()\n",
    "            curLoss.backward()\n",
    "            optimizer.step()\n",
    "        if(curEpoch % 5==0):\n",
    "            print(\"{0} TotalLoss {1}\".format(curEpoch,totalLoss))\n",
    "        if(curEpoch %100==0):\n",
    "            torch.save(model,\"ColoredFaceDetectionModel\")\n",
    "print(\"Cell Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for B&W Classification\n",
    "# Create the trainX and trainY after manually marking the facial with an undescore at the beginning of the file name\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model1=torch.load(\"ColoredFaceDetectionModel\")\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "folders=['00000','01000','02000','03000']\n",
    "for curFolder in folders:\n",
    "    for curFile in os.listdir(curFolder):\n",
    "        curImg=cv2.imread('{0}/{1}'.format(curFolder,curFile))\n",
    "        trainX.append(curImg)\n",
    "        modelVal=model1(Variable(torch.from_numpy(curImg.reshape(1,3,128,128).astype(np.float32))).cuda()).cpu().detach().numpy()[0][0]\n",
    "        trainY.append(modelVal)\n",
    "\n",
    "trainX=np.array(trainX)\n",
    "trainY=[1 if x >0.2 else 0 for x in trainY]\n",
    "trainY=np.array(trainY)\n",
    "\n",
    "# Save the array\n",
    "np.save(\"trainXGAN\",trainX)\n",
    "np.save(\"trainYGAN\",trainY)\n",
    "\n",
    "print(\"Cell Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trainX=np.load(\"trainXGAN.npy\")\n",
    "trainY=np.load(\"trainYGAN.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,latentDim,numClasses):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latentDim=latentDim*latentDim\n",
    "        self.numClasses=numClasses\n",
    "        self.label_emb = nn.Embedding(2,self.latentDim).cuda()\n",
    "        # The GAN Generator will be a CNN\n",
    "        self.conv1=nn.Conv2d(1,4,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max1=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv2=nn.Conv2d(4,8,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max2=nn.MaxPool2d(2, stride=1).cuda()\n",
    "        self.conv3=nn.Conv2d(8,32,(2,2), stride=1, padding=0).cuda()\n",
    "        self.max3=nn.MaxPool2d(2, stride=1).cuda()\n",
    "        self.conv4=nn.Conv2d(32,64,(2,2), stride=1, padding=0).cuda()\n",
    "        self.max4=nn.MaxPool2d(2, stride=1).cuda()\n",
    "        self.conv5=nn.Conv2d(64,64,(2,2), stride=1, padding=0).cuda()\n",
    "        self.max5=nn.MaxPool2d(2, stride=1).cuda()\n",
    "        self.conv6=nn.Conv2d(64,3,(2,2), stride=1, padding=0).cuda()\n",
    "        self.max6=nn.MaxPool2d(2, stride=1).cuda()\n",
    "        self.l1=nn.Linear(3*116*116,3*128*128).cuda()\n",
    "\n",
    "    def forward(self, noise, labelVal):\n",
    "        gen_input = torch.mul(noise,self.label_emb(labelVal)).view(-1,1,256,256).cuda()\n",
    "        out=self.conv1(gen_input).cuda()\n",
    "        out=self.max1(out).cuda()\n",
    "        out=self.conv2(out).cuda()\n",
    "        out=self.max2(out).cuda()\n",
    "        out=self.conv3(out).cuda()\n",
    "        out=self.max3(out).cuda()\n",
    "        out=self.conv4(out).cuda()\n",
    "        out=self.max4(out).cuda()\n",
    "        out=self.conv5(out).cuda()\n",
    "        out=self.max5(out).cuda()\n",
    "        out=self.conv6(out).cuda()\n",
    "        out=self.max6(out).cuda()\n",
    "        out=self.l1(out).view(-1,3,128,128).cuda()\n",
    "        print(out.size())\n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,numClasses):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.numClasses=numClasses\n",
    "        self.conv1=nn.Conv2d(1,4,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max1=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv2=nn.Conv2d(4,8,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max2=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv3=nn.Conv2d(8,16,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max3=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv4=nn.Conv2d(16,64,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max4=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.conv5=nn.Conv2d(64,64,(3,3), stride=1, padding=0).cuda()\n",
    "        self.max5=nn.MaxPool2d(2, stride=2).cuda()\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(45, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(45, self.numClasses), nn.Softmax())\n",
    "\n",
    "    def forward(self, discrim_input):\n",
    "        out=self.conv1(discrim_input).cuda()\n",
    "        out=self.max1(out).cuda()\n",
    "        out=self.conv2(out).cuda()\n",
    "        out=self.max2(out).cuda()\n",
    "        out=self.conv3(out).cuda()\n",
    "        out=self.max3(out).cuda()\n",
    "        out=self.conv4(out).cuda()\n",
    "        out=self.max4(out).cuda()\n",
    "        out=self.conv5(out).cuda()\n",
    "        out=self.max5(out).cuda()\n",
    "        out=self.conv6(out).cuda()\n",
    "        out=self.max6(out).cuda()\n",
    "        print(out.size())\n",
    "        validity=self.adv_layer(out).cuda()\n",
    "        label=self.aux_layer(out).cuda()\n",
    "        return validity,label\n",
    "    \n",
    "print(\"Cell Execution Completed\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "beta1=0.1\n",
    "beta2=0.01\n",
    "latentDim=256\n",
    "numClasses=2\n",
    "epochs=1\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "\n",
    "generator = Generator(latentDim,2)\n",
    "discriminator = Discriminator(2)\n",
    "learningRateG=0.00001\n",
    "learningRateD=0.001\n",
    "generatorExtraCount=8\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learningRateG)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learningRateD)\n",
    "\n",
    "FloatTensor = torch.FloatTensor\n",
    "LongTensor = torch.LongTensor  \n",
    "batchSize=4\n",
    "numBatches=1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    totalGLoss=0\n",
    "    totalDLoss=0\n",
    "    for curBatch in range(numBatches):\n",
    "        #inpData=curData[choiceList,:].astype(np.float32)\n",
    "        #labels=labelVals[choiceList].astype(np.int)\n",
    "        real_imgs=Variable(torch.from_numpy(trainX[curBatch*batchSize:(curBatch+1)*batchSize].reshape(batchSize,3,128,128).astype(np.float32))).cuda()\n",
    "        labels=Variable(torch.from_numpy(trainY[curBatch*batchSize:(curBatch+1)*batchSize])).cuda()\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batchSize, 1).fill_(1.0), requires_grad=False).cuda()\n",
    "        fake = Variable(FloatTensor(batchSize, 1).fill_(0.0), requires_grad=False).cuda()\n",
    "\n",
    "        # GENERATOR TRAINING\n",
    "        # Set the gradients for the Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        # Sample noise and random labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batchSize, latentDim*latentDim)))).cuda()\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, numClasses, batchSize))).cuda()\n",
    "        # Generate a batch of data\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        print(\"Size of gen_imgs is {0}\".format(gen_imgs.size()))\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity,pred_label = discriminator(gen_imgs)\n",
    "        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # DISCRIMINATOR TRAINING\n",
    "        optimizer_D.zero_grad()\n",
    "        #Loss for real images\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        # Calculate discriminator accuracy\n",
    "        #pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        #gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "        #d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        totalGLoss=totalGLoss + g_loss.item()\n",
    "        totalDLoss=totalDLoss + d_loss.item()\n",
    "    if(epoch %1==0):\n",
    "        print(\"[Epoch {0}/{1}] [D loss:{2}] [G loss: {3}]\".format(epoch, epochs, totalDLoss,totalGLoss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
